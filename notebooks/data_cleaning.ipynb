{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from flatten_json import flatten\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collect all raw files into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv files and json files that do not require flattening or parsing\n",
    "data_paths_standard = [\n",
    "            '/Users/antoninalightfoot/Library/Mobile Documents/com~apple~CloudDocs/Documents/TLU/Data analysis/data/Met/MetObjects.csv',\n",
    "            '/Users/antoninalightfoot/Library/Mobile Documents/com~apple~CloudDocs/Documents/TLU/Data analysis/data/Reina Sofia/raw_data/reina_sofia3.csv',\n",
    "            '/Users/antoninalightfoot/Documents/GitHub/museum_personal/data/Tate/tate_raw.csv',\n",
    "            '/Users/antoninalightfoot/Library/Mobile Documents/com~apple~CloudDocs/Documents/TLU/Data analysis/data/Centre Pompidou/merged_file.json',\n",
    "            '/Users/antoninalightfoot/Documents/GitHub/museum_personal/data/Moma/Artworks.csv',\n",
    "            '/Users/antoninalightfoot/Documents/GitHub/museum_personal/data/Whitneymuseum/whitney_data_raw.csv',\n",
    "            '/Users/antoninalightfoot/Documents/GitHub/museum_personal/data/National Gallery (DC)/national_gallery_raw.csv',\n",
    " ] \n",
    "raw_data = []\n",
    "for df in data_paths_standard:\n",
    "    # Step 1: Check if '.json' exists in the input\n",
    "    if '.json' in df:\n",
    "        data = pd.read_json(df)\n",
    "    elif '.csv' in df:\n",
    "        data = pd.read_csv(df, on_bad_lines='skip', low_memory=False)\n",
    "    else:\n",
    "        print(\"Cannot load \" + df)\n",
    "    raw_data.append(data)\n",
    "   \n",
    "\n",
    "dataset_names = [\n",
    "    'met',\n",
    "    'reina_sofia',\n",
    "    'tate',\n",
    "    'pompidou',\n",
    "    'moma',\n",
    "    'whitney',\n",
    "    'national_gallery'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets that require flattening\n",
    "data_paths_flattening = [\n",
    "    '/Users/antoninalightfoot/Library/Mobile Documents/com~apple~CloudDocs/Documents/TLU/Data analysis/data/Kiasma/APIexample-master/dataset.json', # Kiasma]\n",
    "    '/Users/antoninalightfoot/Documents/GitHub/museum_personal/data/SMK/smk_all_da.json',\n",
    "    '/Users/antoninalightfoot/Library/Mobile Documents/com~apple~CloudDocs/Documents/TLU/Data analysis/data/Kiasma/APIexample-master/dataset.json', #Ateneum\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the dictionary\n",
    "flat_data = []\n",
    "dictionary_data = []\n",
    "for df in data_paths_flattening:\n",
    "    with open(df, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        dictionary_data.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dictionary_data:\n",
    "    flattened_data = [flatten(record) for record in df]\n",
    "\n",
    "    # Step 3: Convert flattened data to pandas DataFrame\n",
    "    data = pd.DataFrame(flattened_data)\n",
    "    flat_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate kiasma and ateneum\n",
    "flat_data[0] = flat_data[0][flat_data[0]['responsibleOrganisation'] == 'Kansallisgalleria / Nykytaiteen museo Kiasma']\n",
    "flat_data[2] = flat_data[2][flat_data[2]['responsibleOrganisation'] == 'Kansallisgalleria / Ateneumin taidemuseo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58264 entries, 0 to 58263\n",
      "Columns: 499 entries, objectId to keywords_43_sv\n",
      "dtypes: float64(118), int64(1), object(380)\n",
      "memory usage: 221.8+ MB\n"
     ]
    }
   ],
   "source": [
    "flat_data[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datasets = ['kiasma', 'smk', 'ateneum']\n",
    "dataset_names.extend(new_datasets)\n",
    "raw_data.extend(flat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# File path to the raw JSON data\n",
    "data_path = '/Users/antoninalightfoot/Documents/GitHub/museum_personal/data/Queensland/raw_data.json'\n",
    "\n",
    "# Load the JSON data\n",
    "with open(data_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the column names from the \"fields\" part of the JSON\n",
    "columns = [field['id'] for field in data['fields']]\n",
    "\n",
    "# Extract the records (the data)\n",
    "records = data['records']\n",
    "\n",
    "# Create the DataFrame\n",
    "queensland = pd.DataFrame(records, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names.append('queensland')\n",
    "raw_data.append(queensland)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create functions for cleaning fields.\n",
    "artist name, artwork title, artwork medium, and acquisition source, aquisition year, creation year, artist nationality, artist gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare queensland for analysis\n",
    "def assign_dates(row, column_name):\n",
    "    text = row[column_name]\n",
    "    \n",
    "    # Use regular expressions to find patterns for years\n",
    "    years = re.findall(r'\\b\\d{4}\\b', text)  # Find all 4-digit numbers\n",
    "    \n",
    "    # If exactly one year is found, it is the birth year\n",
    "    if len(years) == 1:\n",
    "        row['birth_date'] = int(years[0])\n",
    "        row['death_date'] = None  # No death date if only one year is found\n",
    "    # If exactly two years are found, assign the first to birth_date and the second to death_date\n",
    "    elif len(years) >= 2:\n",
    "        row['birth_date'] = int(years[0])\n",
    "        row['death_date'] = int(years[1])\n",
    "    else:\n",
    "        # If no years or more than two years are found, set both to None\n",
    "        row['birth_date'] = None\n",
    "        row['death_date'] = None\n",
    "    \n",
    "    return row\n",
    "\n",
    "raw_data[10]['Artist'] = raw_data[10]['Person'].str.split('\\n').str.get(0)\n",
    "raw_data[10]['Nationality'] = raw_data[10]['Person'].str.split('\\n').str.get(-1).str.split('1').str.get(0)\n",
    "raw_data[10]['birth_date'] = None\n",
    "raw_data[10]['death_date'] = None\n",
    "raw_data[10] = raw_data[10].apply(assign_dates, axis=1, column_name='Person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate columns created with flattening json\n",
    "raw_data[7] = raw_data[7].loc[:, ~raw_data[7].columns.str.startswith('keywords')]\n",
    "raw_data[7] = raw_data[7].loc[:, ~raw_data[7].columns.str.startswith('multimedia')]\n",
    "raw_data[7]['artist_name'] = raw_data[7]['people_0_firstName'] + \" \" + raw_data[7]['people_0_familyName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artist_name(df):\n",
    "    # List of possible column names for the artist name\n",
    "    possible_columns = ['artist', 'author', 'artist_name', 'Artist Display Name', 'artist name', 'Artist Display Name', 'Artist', 'artists', \n",
    "                        'forwarddisplayname', 'production_0_creator']\n",
    "    \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Artist'] = df[col]\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artwork_title(df):\n",
    "    # List of possible column names for the artist name\n",
    "    possible_columns = ['object_title', 'artwork_name', 'Title', 'url', 'name', 'title', 'title_fi', 'titles_0_title']\n",
    "    \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Title'] = df[col]\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artwork_medium(df):\n",
    "    # List of possible column names for the artist name\n",
    "    possible_columns = ['Classification', 'classification', 'classifications_0_en','object_type', 'type_artwork', 'artwork_medium', 'Medium', 'medium',\n",
    "                        'object_names_1_name', 'PhysicalCategory']\n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Medium'] = df[col]\n",
    "            break  # Exit loop once we find the first match\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers(value):\n",
    "    # Check if the value is NaN or not a string/number\n",
    "    if pd.isna(value):  # Check for NaN\n",
    "        return \"\"  # Return empty string and 0 count for NaN values\n",
    "    \n",
    "    # If it's a string, replace symbols with spaces\n",
    "    if isinstance(value, str):  # If it's a string\n",
    "        years = re.findall(r'\\b\\d{4}\\b', value)  # Find all 4-digit numbers\n",
    "        if years:  # If the list is not empty\n",
    "            year = years[0]\n",
    "        else:  # If no years are found, set to a default value\n",
    "            year = \"\"\n",
    "    # If it's an int or float, convert to string and process\n",
    "    elif isinstance(value, (int, float)):  # If it's a number (int or float)\n",
    "        value = str(value)  # Convert to string\n",
    "        years = re.findall(r'\\b\\d{4}\\b', value)  # Try to find 4-digit numbers\n",
    "        if years:  # If the list is not empty\n",
    "            year = years[0]\n",
    "        else:  # If no years are found, set to a default value\n",
    "            year = \"\"\n",
    "      \n",
    "    return year\n",
    "\n",
    "    \n",
    "def clean_acquisition_year(df):\n",
    "   # List of possible column names for the artist name\n",
    "    possible_columns = ['acquisition_date', 'credit_line', 'AccessionYear', 'artwork_acquisition', 'year_adquisition', 'acquisitionYear',\n",
    "                        'DateAcquired', 'accession_number', 'accessionnum', 'inventoryNumber', 'acquisition_date_precision', 'AcquiredDate' ]\n",
    "    df['Year_acquisition'] = pd.NA\n",
    "  \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Year_acquisition'] = df[col].apply(extract_numbers)\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use functions for raw datasets and dreate a new list with clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to add more tags based on dataset values\n",
    "def classify_medium(df):\n",
    "    df['Medium_classified'] = pd.NA\n",
    "    medium_tags = [['paper', 'watercolor', 'card', 'watercolour', 'board', 'chalk', 'mixed', 'print', 'parchment', 'graphic',\n",
    "                    'engraving', 'etching', 'dessin'], #graphics\n",
    "                   ['oil', 'canvas', 'paint', 'fresco', 'painting', 'peinture'], #painting\n",
    "                   ['bronze', 'granite', 'marble', 'alabaster', 'clay', 'iron', 'cement', 'concrete', 'plaster', 'sculpture'], #sculpture\n",
    "                   ['film', 'video'], #video art\n",
    "                   ['fabric', 'glass', 'wood', 'aluminium', 'steel', 'plastic', 'book', 'copper', 'stone', \n",
    "                    'slate', 'wool', 'willow', 'cedar', 'wax', 'walnut', 'tin', 'plate', 'textile', 'terracota', \n",
    "                    'mahogany', 'pine', 'oak', 'iron', 'suede', 'brass', 'sheet', 'cast', 'acacia', 'metal', 'beech', 'celluloid',\n",
    "                    'cellulose', 'ceramic', 'rubber', 'elm', 'earthenware', 'epoxy', 'felt', 'firebricks', 'flint', 'banknote',\n",
    "                    'ivory', 'lead', 'leather', 'terracota', 'perspex', 'resin', 'quartz', 'porcelain', 'object', 'medal',  'silk', 'cotton', 'cashmere'], #object\n",
    "                   ['boat', 'structure', 'burlap', 'bean', 'hook', 'knive', 'hat', 'light', 'wall', 'machine', \n",
    "                    'vinyl', 'cleaner', 'door', 'mirror', 'form', 'metronome', 'sock', 'carpet', 'latex', 'installation'], #installation\n",
    "                   ['photo'], #photography\n",
    "                   ['software', 'audio', 'slide', 'digital', 'net', 'sound'], #new media\n",
    "                   ['architecture'], #architecture\n",
    "                   ]\n",
    "    medium_name = ['graphics', 'painting', 'sculpture', 'video art', 'object', 'installation', 'photography', 'new media', 'architecture']\n",
    "     # Iterate over each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        medium = row['Medium']  # Assuming the column is named 'Medium'\n",
    "        \n",
    "        # Skip if the 'Medium' value is not a string (e.g., NaN or other types)\n",
    "        if not isinstance(medium, str):\n",
    "            continue\n",
    "        \n",
    "        # Check each tag group (e.g., ['paper', 'watercolor'], ['oil'])\n",
    "        for i, tag_group in enumerate(medium_tags):\n",
    "            # Check if any keyword from the tag group exists in the 'Medium' column\n",
    "            if any(tag.lower() in medium.lower() for tag in tag_group):\n",
    "                # Assign the corresponding medium name (from medium_name list)\n",
    "                df.at[idx, 'Medium_classified'] = medium_name[i]\n",
    "                break  # Stop once we find a match\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['austrian', 'french', '', ..., 'filipino american', ' thai',\n",
       "       'hunkpapa lakota'], dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[4]['nationality_raw'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i need to update the dictionary so all nationalities will be translated into countries\n",
    "def create_artist_nationality(df):\n",
    "    possible_columns = ['Country','Artist Nationality', 'nationality_artist', 'artist_nationality', 'Nationality', 'nationality', \n",
    "                        'production_0_creator_nationality']\n",
    "    df['Country_calculated'] = pd.NA\n",
    "    df['nationality_raw'] = pd.NA\n",
    "\n",
    "    # Dictionary to map nationalities to countries\n",
    "    nationality_to_country = {\n",
    "    'american': 'United States',\n",
    "    'américaine': 'United States',\n",
    "    'allemande': 'Germany',\n",
    "    'canadian': 'Canada',\n",
    "    'canadienne': 'Canada',\n",
    "    'japanese': 'Japan',\n",
    "    'japonaise': 'Japan',\n",
    "    'mexican': 'Mexico',\n",
    "    'mexicaine': 'Mexico',\n",
    "    'indian': 'India',\n",
    "    'française': 'France',\n",
    "    'russe': 'Russia',\n",
    "    'suisse': 'Switzerland',\n",
    "    'britannique': 'United Kingdom',\n",
    "    'hongroise': 'Hungary',\n",
    "    'argentine': 'Argentina',\n",
    "    'polonaise': 'Poland',\n",
    "    'yougoslave': 'Yugoslavia',\n",
    "    'suédoise': 'Sweden',\n",
    "    'soviétique': 'Soviet Union',\n",
    "    'italienne': 'Italy',\n",
    "    'espagnole': 'Spain',\n",
    "    'brésilienne': 'Brazil',\n",
    "    'égyptienne': 'Egypt',\n",
    "    'vénézuélienne': 'Venezuela',\n",
    "    'israélienne': 'Israel',\n",
    "    'cubaine': 'Cuba',\n",
    "    'iranienne': 'Iran',\n",
    "    'algérienne': 'Algeria',\n",
    "    'ukrainienne': 'Ukraine',\n",
    "    'roumaine': 'Romania',\n",
    "    'belge': 'Belgium',\n",
    "    'néerlandaise': 'Netherlands',\n",
    "    'apatride': 'Stateless',\n",
    "    'autrichienne': 'Austria',\n",
    "    'irlandaise': 'Ireland',\n",
    "    'portugaise': 'Portugal',\n",
    "    'jordanienne': 'Jordan',\n",
    "    'australienne': 'Australia',\n",
    "    'croate': 'Croatia',\n",
    "    'tchèque': 'Czech Republic',\n",
    "    'albanaise': 'Albania',\n",
    "    'sud-africaine': 'South Africa',\n",
    "    'irakienne': 'Iraq',\n",
    "    'libanaise': 'Lebanon',\n",
    "    'estonienne': 'Estonia',\n",
    "    'kosovare': 'Kosovo',\n",
    "    'marocaine': 'Morocco',\n",
    "    'ivoirienne': 'Ivory Coast',\n",
    "    'arménienne': 'Armenia',\n",
    "    'chinoise': 'China',\n",
    "    'vietnamienne': 'Vietnam',\n",
    "    'tchécoslovaque': 'Czechoslovakia'\n",
    "}\n",
    "\n",
    "\n",
    "    # Check each possible column for nationality information\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['nationality_raw'] = df[col].str.replace('(', '').str.replace(')', '').str.lower()  # Copy the nationality info into 'nationality_raw'\n",
    "            break  # Exit loop once we find the first match \n",
    "\n",
    "    # Replace nationalities in 'nationality_raw' with country names\n",
    "    df['Country_calculated'] = df['nationality_raw'].replace(nationality_to_country)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_artist_gender(df):\n",
    "    possible_columns = ['Artist Gender', 'gender', 'artist_gender', 'Gender', 'production_0_creator_gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acquisition_method(df):\n",
    "    possible_columns = ['Credit Line', 'creditLine', 'acquisition_type', 'CreditLine', 'credit_line', 'creditline', 'CreditLine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artwork_creation_date(df):\n",
    "    possible_columns = ['Object Date', 'year_production', 'year', 'object_date', 'Date', 'display_date', 'endyear_x', 'yearFrom', \n",
    "                        'production_date_0_end', 'DateCreated']\n",
    "    \n",
    "    df['Date_creation_year'] = pd.NA\n",
    "  \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Date_creation_year'] = df[col].apply(extract_numbers)\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_birth_year(df):\n",
    "    possible_columns = ['Artist Begin Date', 'author_born_year', 'yearOfBirth', 'artist_birth', 'BeginDate', 'birth_date', \n",
    "                        'beginyear', 'people_0_birthDate', 'production_0_creator_date_of_birth']\n",
    "    df['Artist_birth_year'] = pd.NA\n",
    "  \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Artist_birth_year'] = df[col].apply(extract_numbers)\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_death_year(df):\n",
    "    possible_columns = ['Artist End Date', 'author_death_year', 'yearOfDeath', 'artist_death', 'EndDate', 'death_date', 'endyear', \n",
    "                        'people_0_deathDate', 'production_0_creator_date_of_death']\n",
    "    df['Artist_death_year'] = pd.NA\n",
    "  \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Artist_death_year'] = df[col].apply(extract_numbers)\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = []\n",
    "for df in raw_data:\n",
    "    #create_artist_name(df)\n",
    "    #create_artwork_title(df)\n",
    "    #create_artwork_medium(df)\n",
    "    #clean_acquisition_year(df)\n",
    "    #classify_medium(df)\n",
    "    #create_artist_nationality(df)\n",
    "    #artwork_creation_date(df)\n",
    "    #artist_birth_year(df)\n",
    "    #artist_death_year(df)\n",
    "    transformed_data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = transformed_data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save clean datasets in separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i need to add more colums to the final dataset\n",
    "clean_data = []\n",
    "for df in transformed_data:\n",
    "    df = df[[ 'Artist', 'Title','Medium', 'Year_acquisition', 'Medium_classified']]\n",
    "    clean_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved met_clean.csv\n",
      "Saved reina_sofia_clean.csv\n",
      "Saved tate_clean.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save each dataset using the corresponding name\n",
    "for dataset, name in zip(clean_data, dataset_names):\n",
    "    # Generate a unique filename using the dataset name\n",
    "    file_name = f\"{name}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    dataset.to_csv(file_name, index=False)\n",
    "    print(f\"Saved {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
