{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the CSV files\n",
    "whitney_artworks = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/whitney/artworks.csv')\n",
    "whitney_artists = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/whitney/artists.csv')\n",
    "\n",
    "# Convert 'id' column to 'artist_ids' as strings without .0 for integer values\n",
    "whitney_artists['artist_ids'] = whitney_artists['id'].apply(lambda x: str(int(x)) if x.is_integer() else str(x))\n",
    "\n",
    "# Ensure that 'artist_ids' column in whitney_artworks is of string type\n",
    "whitney_artworks['artist_ids'] = whitney_artworks['artist_ids'].astype(str)\n",
    "\n",
    "# Merging the two dataframes on 'artist_ids'\n",
    "whitney = whitney_artworks.merge(whitney_artists, on=\"artist_ids\", how='left')\n",
    "\n",
    "# Displaying the result\n",
    "whitney.head()\n",
    "whitney_artists.to_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/whitney/whitney_data_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vh/0cdmtg494k7fs4m0gdhw8vtw0000gp/T/ipykernel_71060/3305933127.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tate_artworks = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/Tate/artwork_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# tate dataset\n",
    "import pandas as pd\n",
    "tate_artworks = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/Tate/artwork_data.csv')\n",
    "tate_artists = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/Tate/artist_data.csv')\n",
    "\n",
    "# Convert 'id' column to 'artist_ids' as strings without .0 for integer values\n",
    "tate_artists['ID'] = tate_artists['id']\n",
    "\n",
    "# Ensure that 'artist_ids' column in tate_artworks is of string type\n",
    "tate_artworks['ID'] = tate_artworks['artistId']\n",
    "\n",
    "# Merging the two dataframes on 'artist_ids'\n",
    "tate = tate_artworks.merge(tate_artists, on=\"ID\", how='left')\n",
    "tate.head()\n",
    "tate.to_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/Tate/tate_raw.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vh/0cdmtg494k7fs4m0gdhw8vtw0000gp/T/ipykernel_71060/1681967053.py:3: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nga_artworks = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/national gallery (DC)/objects.csv')\n"
     ]
    }
   ],
   "source": [
    "#national gallery dataset\n",
    "\n",
    "nga_artworks = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/national gallery (DC)/objects.csv')\n",
    "nga_obj_const = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/national gallery (DC)/objects_constituents.csv')\n",
    "nga_artists = pd.read_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/national gallery (DC)/constituents.csv')\n",
    "\n",
    "nga1 = nga_artworks.merge(nga_obj_const, on=\"objectid\", how='left')\n",
    "\n",
    "nga2 = nga1.merge(nga_artists, on=\"constituentid\", how='left')\n",
    "nga3 = nga2[nga2['roletype'] == 'artist']\n",
    "nga_final = nga3.drop_duplicates(subset='objectid', keep='first')\n",
    "nga_final.to_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/national gallery (DC)/national_gallery_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded flattened data with shape: (58264, 499)\n",
      "Loaded flattened data with shape: (175525, 2877)\n",
      "Loaded flattened data with shape: (58264, 499)\n"
     ]
    }
   ],
   "source": [
    "#flatten jsons and save them as csvs\n",
    "import pandas as pd\n",
    "from flatten_json import flatten\n",
    "import json\n",
    "\n",
    "data_paths_flattening = [\n",
    "        \"/Users/CUDAN/Documents/TLU/Data analysis/data/Kiasma/APIexample-master/dataset.json\",  # Kiasma\n",
    "        \"/Users/CUDAN/Documents/TLU/Data analysis/data/smk/smk_all_da.json\",\n",
    "        \"/Users/CUDAN/Documents/TLU/Data analysis/data/Kiasma/APIexample-master/dataset.json\",  # Ateneum\n",
    "    ]\n",
    "flat_data = []\n",
    "dictionary_data = []\n",
    "for df in data_paths_flattening:\n",
    "        with open(df, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            dictionary_data.append(data)\n",
    "\n",
    "for df in dictionary_data:\n",
    "        flattened_data = [flatten(record) for record in df]\n",
    "        data = pd.DataFrame(flattened_data)\n",
    "        flat_data.append(data)\n",
    "        print(f\"Loaded flattened data with shape: {data.shape}\")\n",
    "\n",
    "    # Separate kiasma and ateneum\n",
    "flat_data[0] = flat_data[0][\n",
    "        flat_data[0][\"responsibleOrganisation\"]\n",
    "        == \"Kansallisgalleria / Nykytaiteen museo Kiasma\"\n",
    "    ]\n",
    "flat_data[2] = flat_data[2][\n",
    "        flat_data[2][\"responsibleOrganisation\"]\n",
    "        == \"Kansallisgalleria / Ateneumin taidemuseo\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = flat_data[0].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify kiasma\n",
    "# Extract the 'materials_' columns, row by row\n",
    "# Join the values in each row into a single string\n",
    "flat_data[0]['medium'] = flat_data[0].filter(regex='^materials_').apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
    "flat_data[0]['acquisition?'] = flat_data[0]['acquisitionYear']\n",
    "# Drop columns matching regex patterns: 'keywords', 'multimedia', '_sv'\n",
    "patterns_to_drop = ['keywords', 'multimedia', '_sv', 'materials', 'birthPlace', 'deathPlace', 'collection', 'role', 'attribution', 'acquisitionYear']\n",
    "for pattern in patterns_to_drop:\n",
    "    flat_data[0].drop(flat_data[0].filter(regex=pattern).columns, axis=1, inplace=True)\n",
    "flat_data[0].dropna(axis=1, how='all', inplace=True)\n",
    "flat_data[0][\"artist_name\"] = (\n",
    "        flat_data[0][\"people_0_firstName\"] + \" \" + flat_data[0][\"people_0_familyName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify ateneum\n",
    "# Extract the 'materials_' columns, row by row\n",
    "# Join the values in each row into a single string\n",
    "flat_data[2]['medium'] = flat_data[2].filter(regex='^materials_').apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
    "# Drop columns matching regex patterns: 'keywords', 'multimedia', '_sv'\n",
    "patterns_to_drop = ['keywords', 'multimedia', '_sv', 'materials', 'birthPlace', 'deathPlace', 'collection', 'role', 'attribution']\n",
    "for pattern in patterns_to_drop:\n",
    "    flat_data[2].drop(flat_data[2].filter(regex=pattern).columns, axis=1, inplace=True)\n",
    "flat_data[2].dropna(axis=1, how='all', inplace=True)\n",
    "flat_data[2][\"artist_name\"] = (\n",
    "        flat_data[2][\"people_0_firstName\"] + \" \" + flat_data[2][\"people_0_familyName\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplify smk\n",
    "#drop columns\n",
    "flat_data[1].dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "flat_data[1] = flat_data[1][['id', 'acquisition_date', 'dimensions_0_unit', 'dimensions_0_value', 'dimensions_1_unit', \n",
    "                            'dimensions_1_value', 'artist_0', 'titles_0_title', 'production_0_creator_gender',\n",
    "                            'production_0_creator_nationality', 'credit_line_0', 'production_date_0_end', \n",
    "                            'production_0_creator_date_of_birth', 'production_0_creator_date_of_death',\n",
    "                            'object_names_0_name', 'object_names_1_name']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = flat_data[1].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data[0].to_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/Kiasma/APIexample-master/kiasma_flattened.csv')\n",
    "flat_data[1].to_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/smk/smk_flattened.csv')\n",
    "flat_data[2].to_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/Kiasma/APIexample-master/ateneum_flattened.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded queensland with shape: (20250, 17)\n"
     ]
    }
   ],
   "source": [
    "# simplify queensland\n",
    "import re\n",
    "# File path to the raw JSON data\n",
    "data_path = \"/Users/CUDAN/Documents/TLU/Data analysis/data/queensland/raw_data.json\"\n",
    "\n",
    "    # Load the JSON data\n",
    "with open(data_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Extract the column names from the \"fields\" part of the JSON\n",
    "columns = [field[\"id\"] for field in data[\"fields\"]]\n",
    "\n",
    "    # Extract the records (the data)\n",
    "records = data[\"records\"]\n",
    "\n",
    "    # Create the DataFrame\n",
    "queensland = pd.DataFrame(records, columns=columns)\n",
    "print(f\"Loaded queensland with shape: {queensland.shape}\")\n",
    "\n",
    "    # Prepare queensland for analysis\n",
    "def assign_dates(row, column_name):\n",
    "        text = row[column_name]\n",
    "\n",
    "        # Use regular expressions to find patterns for years\n",
    "        years = re.findall(r\"\\b\\d{4}\\b\", text)  # Find all 4-digit numbers\n",
    "\n",
    "        # If exactly one year is found, it is the birth year\n",
    "        if len(years) == 1:\n",
    "            row[\"birth_date\"] = int(years[0])\n",
    "            row[\"death_date\"] = None  # No death date if only one year is found\n",
    "        # If exactly two years are found, assign the first to birth_date and the second to death_date\n",
    "        elif len(years) >= 2:\n",
    "            row[\"birth_date\"] = int(years[0])\n",
    "            row[\"death_date\"] = int(years[1])\n",
    "        else:\n",
    "            # If no years or more than two years are found, set both to None\n",
    "            row[\"birth_date\"] = None\n",
    "            row[\"death_date\"] = None\n",
    "\n",
    "        return row\n",
    "queensland[\"Artist\"] = queensland[\"Person\"].str.split(\"\\n\").str.get(0)\n",
    "queensland[\"Nationality\"] = (\n",
    "        queensland[\"Person\"].str.split(\"\\n\").str.get(-1).str.split(\"1\").str.get(0)\n",
    "    )\n",
    "queensland[\"birth_date\"] = None\n",
    "queensland[\"death_date\"] = None\n",
    "queensland = queensland.apply(assign_dates, axis=1, column_name=\"Person\")\n",
    "queensland.to_csv('/Users/CUDAN/Documents/TLU/Data analysis/data/queensland/queensland_flattened.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
