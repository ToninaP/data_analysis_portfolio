{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cleaning_scripts.load_data_to_clean2 import load_data_to_clean\n",
    "from cleaning_scripts.string_operations import create_artist_name_col, create_artwork_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded met with shape: (476318, 54)\n",
      "Loaded reina_sofia with shape: (10018, 16)\n",
      "Loaded tate with shape: (69201, 31)\n",
      "Loaded pompidou with shape: (115217, 23)\n",
      "Loaded moma with shape: (157474, 30)\n",
      "Loaded whitney with shape: (26497, 21)\n",
      "Loaded national_gallery with shape: (141438, 55)\n",
      "Loaded kiasma with shape: (8329, 70)\n",
      "Loaded smk with shape: (175525, 17)\n",
      "Loaded ateneum with shape: (27994, 88)\n",
      "Loaded queensland with shape: (20250, 22)\n"
     ]
    }
   ],
   "source": [
    "raw_data, dataset_names = load_data_to_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create functions for cleaning fields.\n",
    "artist name, artwork title, artwork medium, and acquisition source, aquisition year, creation year, artist nationality, artist gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist name found in column: Artist Display Name\n",
      "Artist name found in column: author\n",
      "Artist name found in column: artist\n",
      "Artist name found in column: artist_name\n",
      "Artist name found in column: Artist\n",
      "Artist name found in column: artists\n",
      "Artist name found in column: forwarddisplayname\n",
      "Artist name found in column: artist_name\n",
      "Artist name found in column: artist_0\n",
      "Artist name found in column: artist_name\n",
      "Artist name found in column: Artist\n"
     ]
    }
   ],
   "source": [
    "#create a new column with Artist name\n",
    "transformed_data = []\n",
    "for df in raw_data:\n",
    "    create_artist_name_col(df)\n",
    "    transformed_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artwork title found in column: Title\n",
      "Artwork title found in column: name\n",
      "Artwork title found in column: name\n",
      "Artwork title found in column: object_title\n",
      "Artwork title found in column: Title\n",
      "Artwork title found in column: title\n",
      "Artwork title found in column: title\n",
      "Artwork title found in column: title_fi\n",
      "Artwork title found in column: titles_0_title\n",
      "Artwork title found in column: title_fi\n",
      "Artwork title found in column: Title\n"
     ]
    }
   ],
   "source": [
    "#create a new column with Artwork title\n",
    "for df in transformed_data:\n",
    "    create_artwork_title(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26497 entries, 0 to 26496\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         26497 non-null  int64  \n",
      " 1   id_x               26497 non-null  int64  \n",
      " 2   title              26497 non-null  object \n",
      " 3   display_date       26493 non-null  object \n",
      " 4   classification     26497 non-null  object \n",
      " 5   medium             26491 non-null  object \n",
      " 6   accession_number   26497 non-null  object \n",
      " 7   dimensions         25999 non-null  object \n",
      " 8   publication_info   5752 non-null   object \n",
      " 9   edition            11706 non-null  object \n",
      " 10  credit_line        26493 non-null  object \n",
      " 11  credit_line_repro  16188 non-null  object \n",
      " 12  artists            26497 non-null  object \n",
      " 13  artist_ids         26497 non-null  object \n",
      " 14  artist_id          26497 non-null  int64  \n",
      " 15  id_y               26497 non-null  float64\n",
      " 16  getty_ulan_id      21261 non-null  float64\n",
      " 17  wikidata_id        24127 non-null  object \n",
      " 18  display_name       26497 non-null  object \n",
      " 19  birth_date         26497 non-null  float64\n",
      " 20  death_date         26497 non-null  float64\n",
      " 21  Artist             26497 non-null  object \n",
      " 22  Title              26497 non-null  object \n",
      "dtypes: float64(4), int64(3), object(16)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "transformed_data[5].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to add more tags based on dataset values\n",
    "from medium_tags import load_medium_tags #returns medium_tags, medium_name\n",
    "medium_tags, medium_name = load_medium_tags()\n",
    "def classify_medium(df):\n",
    "    df['Medium_classified'] = pd.NA\n",
    "    \n",
    "     # Iterate over each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        medium = row['Medium_raw'] \n",
    "        \n",
    "        # Skip if the 'Medium' value is not a string (e.g., NaN or other types)\n",
    "        if not isinstance(medium, str):\n",
    "            continue\n",
    "        \n",
    "        # Check each tag group (e.g., ['paper', 'watercolor'], ['oil'])\n",
    "        for i, tag_group in enumerate(medium_tags):\n",
    "            # Check if any keyword from the tag group exists in the 'Medium' column\n",
    "            if any(tag.lower() in medium.lower() for tag in tag_group):\n",
    "                # Assign the corresponding medium name (from medium_name list)\n",
    "                df.at[idx, 'Medium_classified'] = medium_name[i]\n",
    "                break  # Stop once we find a match\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i need to update the dictionary so all nationalities will be translated into countries\n",
    "from load_nationality_tags import load_nationality_tags\n",
    "nationality_tags, country_name = load_nationality_tags()\n",
    "def create_artist_nationality(df):\n",
    "    possible_columns = ['Country','Artist Nationality', 'nationality_artist', 'artist_nationality', 'Nationality', 'nationality', \n",
    "                        'production_0_creator_nationality']\n",
    "    df['Country_calculated'] = pd.NA\n",
    "    df['nationality_raw'] = pd.NA\n",
    "\n",
    "    # Check each possible column for nationality information\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['nationality_raw'] = df[col].str.lower().str.strip('the').str.replace('(', '').str.replace(')', '').str.split(' ').str[0].str.strip(',')  # Copy the nationality info into 'nationality_raw'\n",
    "            break  # Exit loop once we find the first match \n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        nationality = row['nationality_raw'] \n",
    "        \n",
    "        # Skip if the 'nationality' value is not a string (e.g., NaN or other types)\n",
    "        if not isinstance(nationality, str):\n",
    "            continue\n",
    "        \n",
    "        # Check each tag group (e.g., ['paper', 'watercolor'], ['oil'])\n",
    "        for i, tag_group in enumerate(nationality_tags):\n",
    "            # Check if any keyword from the tag group exists in the 'nationality' column\n",
    "            if any(tag.lower() in nationality.lower() for tag in tag_group):\n",
    "                # Assign the corresponding nationality name (from nationality_name list)\n",
    "                df.at[idx, 'Country_calculated'] = country_name[i]\n",
    "                break  # Stop once we find a match\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use functions for raw datasets and dreate a new list with clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artist_gender(df):\n",
    "    possible_columns = ['Artist Gender', 'gender', 'artist_gender', 'Gender', 'production_0_creator_gender']\n",
    "    # Define a gender dictionary to map common terms to 'female' or 'male'\n",
    "    gender_dict = {'female': [\"female\", 'woman'], 'male': ['male', 'man']}\n",
    "    \n",
    "    # Initialize the 'Gender_raw' column with missing values\n",
    "    df['Gender_raw'] = pd.NA\n",
    "    \n",
    "    # Check which column exists and assign to 'Gender_raw'\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Gender_raw'] = df[col]\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    # Clean the text: remove all non-alphanumeric characters, split by spaces, and use the first word\n",
    "    df['Gender_classified'] = df['Gender_raw'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)  # Remove non-alphabetic characters\n",
    "    df['Gender_classified'] = df['Gender_classified'].str.split().str[0].str.lower()  # Split by space and take the first word\n",
    "\n",
    "    # Manually map \"man\" and \"woman\" to \"male\" and \"female\" directly\n",
    "    df['Gender_classified'] = df['Gender_classified'].replace({'man': 'male', 'woman': 'female'})\n",
    "    \n",
    "    # Use a safe check to apply gender classification only on valid strings\n",
    "    df['Gender_classified'] = df['Gender_classified'].apply(\n",
    "        lambda x: 'female' if isinstance(x, str) and 'female' in x else ('male' if isinstance(x, str) and 'male' in x else x)\n",
    "    )\n",
    "    \n",
    "    # Return the modified DataFrame\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = transformed_data[10][['acquisition_raw', 'Acquistion_classified']].drop_duplicates(subset=['acquisition_raw'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_acquisition_tags import load_acquisition_tags\n",
    "acqusition_tags, acquisition_methods = load_acquisition_tags()\n",
    "def create_acquisition_method(df):\n",
    "    possible_columns = ['Credit Line', 'creditLine', 'acquisition_type', 'CreditLine', 'credit_line', 'creditline', 'CreditLine']\n",
    "     # Initialize the 'Gender_raw' column with missing values\n",
    "    df['acquisition_raw'] = pd.NA\n",
    "    \n",
    "    # Check which column exists and assign to 'Gender_raw'\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['acquisition_raw'] = df[col].str.lower()\n",
    "            break  # Exit loop once we find the first match\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        acquisition = row['acquisition_raw'] \n",
    "        \n",
    "        # Skip if the 'acquisition' value is not a string (e.g., NaN or other types)\n",
    "        if not isinstance(acquisition, str):\n",
    "            continue\n",
    "        \n",
    "        # Check each tag group \n",
    "        for i, tag_group in enumerate(acqusition_tags):\n",
    "            # Check if any keyword from the tag group exists in the 'acquisition' column\n",
    "            if any(tag.lower() in acquisition.lower() for tag in tag_group):\n",
    "                # Assign the corresponding acquisition name (from acquisition_name list)\n",
    "                df.at[idx, 'Acquistion_classified'] = acquisition_methods[i]\n",
    "                break  # Stop once we find a match\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquisition date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artwork_creation_date(df):\n",
    "    possible_columns = ['Object Date', 'year_production', 'year', 'object_date', 'Date', 'display_date', 'endyear_x', 'yearFrom', \n",
    "                        'production_date_0_end', 'DateCreated']\n",
    "    \n",
    "    df['Date_creation_year'] = pd.NA\n",
    "  \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Date_creation_year'] = df[col].apply(extract_first_number)\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_birth_year(df):\n",
    "    possible_columns = ['Artist Begin Date', 'author_born_year', 'yearOfBirth', 'artist_birth', 'BeginDate', 'birth_date', \n",
    "                        'beginyear', 'people_0_birthYear', 'production_0_creator_date_of_birth']\n",
    "    df['Artist_birth_year'] = pd.NA\n",
    "  \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Artist_birth_year'] = df[col].apply(extract_first_number)\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_death_year(df):\n",
    "    possible_columns = ['Artist End Date', 'author_death_year', 'yearOfDeath', 'artist_death', 'EndDate', 'death_date', 'endyear', \n",
    "                        'people_0_deathYear', 'production_0_creator_date_of_death']\n",
    "    df['Artist_death_year'] = pd.NA\n",
    "  \n",
    "    # Loop over the possible column names and use the first one that exists\n",
    "    for col in possible_columns:\n",
    "        if col in df.columns:\n",
    "            df['Artist_death_year'] = df[col].apply(extract_first_number)\n",
    "            break  # Exit loop once we find the first match\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = []\n",
    "for df in raw_data:\n",
    "    create_artist_name(df)\n",
    "    create_artwork_title(df)\n",
    "    create_artwork_medium(df)\n",
    "    classify_medium(df)\n",
    "    create_artist_nationality(df)\n",
    "    artwork_creation_date(df)\n",
    "    clean_acquisition_year(df)\n",
    "    artist_birth_year(df)\n",
    "    artist_death_year(df)\n",
    "    create_artist_gender(df)\n",
    "    create_acquisition_method(df)\n",
    "    transformed_data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Object Number', 'Is Highlight', 'Is Timeline Work', 'Is Public Domain',\n",
       "       'Object ID', 'Gallery Number', 'Department', 'AccessionYear',\n",
       "       'Object Name', 'Title', 'Culture', 'Period', 'Dynasty', 'Reign',\n",
       "       'Portfolio', 'Constituent ID', 'Artist Role', 'Artist Prefix',\n",
       "       'Artist Display Name', 'Artist Display Bio', 'Artist Suffix',\n",
       "       'Artist Alpha Sort', 'Artist Nationality', 'Artist Begin Date',\n",
       "       'Artist End Date', 'Artist Gender', 'Artist ULAN URL',\n",
       "       'Artist Wikidata URL', 'Object Date', 'Object Begin Date',\n",
       "       'Object End Date', 'Medium', 'Dimensions', 'Credit Line',\n",
       "       'Geography Type', 'City', 'State', 'County', 'Country', 'Region',\n",
       "       'Subregion', 'Locale', 'Locus', 'Excavation', 'River', 'Classification',\n",
       "       'Rights and Reproduction', 'Link Resource', 'Object Wikidata URL',\n",
       "       'Metadata Date', 'Repository', 'Tags', 'Tags AAT URL',\n",
       "       'Tags Wikidata URL', 'Artist', 'Medium_raw', 'Medium_classified',\n",
       "       'Country_calculated', 'nationality_raw', 'Date_creation_year',\n",
       "       'Year_acquisition', 'Artist_birth_year', 'Artist_death_year',\n",
       "       'Gender_raw', 'Gender_classified', 'acquisition_raw',\n",
       "       'Acquistion_classified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save clean datasets in separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clean_data = []\n",
    "\n",
    "# Define the desired columns\n",
    "required_columns = ['Artist', 'Title', 'Medium', 'Medium_classified', 'Acquistion_classified', \n",
    "                    'Year_acquisition', 'Gender_classified', 'Artist_birth_year', \n",
    "                    'Artist_death_year', 'Country_calculated', 'Date_creation_year']\n",
    "\n",
    "for df in transformed_data:\n",
    "    # Add any missing columns as NaN\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA  # or use 'None' or 'NaN' depending on your preference\n",
    "\n",
    "    clean_data.append(df[required_columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved met.csv\n",
      "Saved reina_sofia.csv\n",
      "Saved tate.csv\n",
      "Saved pompidou.csv\n",
      "Saved moma.csv\n",
      "Saved whitney.csv\n",
      "Saved national_gallery.csv\n",
      "Saved kiasma.csv\n",
      "Saved smk.csv\n",
      "Saved ateneum.csv\n",
      "Saved queensland.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save each dataset using the corresponding name\n",
    "for dataset, name in zip(clean_data, dataset_names):\n",
    "    # Generate a unique filename using the dataset name\n",
    "    file_name = f\"{name}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    dataset.to_csv(file_name, index=False)\n",
    "    print(f\"Saved {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
